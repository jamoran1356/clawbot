# ğŸ”¬ Web Research Engine

**Motor de investigaciÃ³n web inteligente - Busca, extrae y analiza informaciÃ³n automÃ¡ticamente.**

---

## âš¡ Features

âœ… **BÃºsqueda en Google** - Top resultados automÃ¡ticos  
âœ… **ExtracciÃ³n de Contenido** - Parse HTML + metadata  
âœ… **AnÃ¡lisis Profundo** - Keywords + relevancia  
âœ… **InvestigaciÃ³n Multi-stage** - BÃºsqueda â†’ ExtracciÃ³n â†’ AnÃ¡lisis  
âœ… **CLI Interactivo** - Usa desde terminal  
âœ… **Subagente Support** - Spawn para investigaciones paralelas  
âœ… **Reportes JSON** - Resultados estructurados  
âœ… **No requiere Chrome** - Funciona con requests + BeautifulSoup  

---

## ğŸš€ InstalaciÃ³n

```bash
cd web-research

# Instalar dependencias
pip install --break-system-packages beautifulsoup4 requests lxml

# Crear directorio de resultados
mkdir -p results
```

---

## ğŸ“– Uso

### 1. CLI Interactivo

```bash
python research_cli.py
```

MenÃº:
```
1. BÃºsqueda simple
2. InvestigaciÃ³n profunda
3. InvestigaciÃ³n con subtÃ³picos
4. Salir
```

### 2. CLI Directo

```bash
# BÃºsqueda simple
python research_cli.py "AI 2026"

# Con profundidad
python research_cli.py "FastAPI" --depth 5

# Con subtÃ³picos
python research_cli.py "Web3" --subs "blockchain,crypto,NFTs"
```

### 3. Como Python Module

```python
from research_engine import WebResearchEngine
import asyncio

async def research():
    engine = WebResearchEngine()
    
    # BÃºsqueda simple
    results = await engine.google_search("Python FastAPI")
    
    # InvestigaciÃ³n completa
    research = await engine.search_and_analyze("AI trends", depth=5)
    
    # Con subtÃ³picos
    research = await engine.research_topic(
        "Machine Learning",
        subtopics=["neural networks", "deep learning"]
    )
    
    # Guardar
    engine.save_research(research)
    engine.print_report(research)

asyncio.run(research())
```

### 4. Como Subagente

```python
from sessions_spawn import sessions_spawn

# Spawn investigaciÃ³n en paralelo
await sessions_spawn(
    task="Investiga las tendencias de IA en 2026",
    agentId="research-bot",
    runTimeoutSeconds=300
)

# El subagente automÃ¡ticamente:
# 1. Busca en Google
# 2. Extrae contenido
# 3. Analiza resultados
# 4. Retorna reporte
# 5. Se elimina
```

---

## ğŸ“Š Ejemplo de Salida

```json
{
  "query": "AI 2026",
  "timestamp": "2026-01-29T20:30:00",
  "summary": {
    "total_sources": 10,
    "total_extracted": 8,
    "total_analyzed": 8,
    "avg_relevance": 78.5
  },
  "stages": {
    "search": {
      "total_results": 10,
      "results": [
        {
          "title": "The Future of AI in 2026",
          "url": "https://...",
          "snippet": "AI is transforming...",
          "source": "google"
        }
      ]
    },
    "extraction": {
      "content": [
        {
          "url": "https://...",
          "title": "The Future of AI in 2026",
          "content": "AI is transforming industries..."
        }
      ]
    },
    "analysis": {
      "analyses": [
        {
          "keywords_found": {"AI": 15, "2026": 8},
          "relevance_score": 85,
          "word_count": 1250
        }
      ]
    }
  }
}
```

---

## ğŸ” MÃ©todos Principales

### google_search()
```python
results = await engine.google_search("query", num_results=10)
# Retorna: List[Dict] con title, url, snippet
```

### fetch_page()
```python
content = await engine.fetch_page("https://example.com")
# Retorna: Dict con title, h1, meta_description, content
```

### analyze_content()
```python
analysis = await engine.analyze_content(text, query)
# Retorna: Dict con keywords_found, relevance_score
```

### search_and_analyze()
```python
investigation = await engine.search_and_analyze("query", depth=5)
# Retorna: InvestigaciÃ³n completa multi-stage
```

### research_topic()
```python
research = await engine.research_topic("main", subtopics=[...])
# Retorna: InvestigaciÃ³n del tema + subtÃ³picos
```

### save_research()
```python
path = engine.save_research(research)
# Guarda a JSON en results/
```

---

## ğŸ¯ Casos de Uso

### 1. InvestigaciÃ³n Competitiva
```python
research = await engine.research_topic(
    "FastAPI vs Django vs Express",
    subtopics=["performance", "features", "community"]
)
```

### 2. Market Research
```python
research = await engine.research_topic(
    "AI Startups 2026",
    subtopics=["funding", "applications", "trends"]
)
```

### 3. Fact Checking
```python
query = "Is AI superintelligence possible in 2026?"
research = await engine.search_and_analyze(query, depth=10)
```

### 4. Content Research
```python
research = await engine.research_topic(
    "Web Development Best Practices",
    subtopics=["performance", "accessibility", "security"]
)
```

---

## ğŸ› ï¸ ConfiguraciÃ³n

### Timeout
```python
response = self.session.get(url, timeout=15)  # 15 segundos
```

### Rate Limiting
```python
await asyncio.sleep(1)  # Entre requests
await asyncio.sleep(2)  # Entre investigaciones
```

### User Agent
```python
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
```

### Results Directory
```
web-research/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ research_20260129_203000.json
â”‚   â””â”€â”€ research_20260129_203500.json
â””â”€â”€ ...
```

---

## âš ï¸ Limitaciones (v1)

- âŒ Sin JavaScript execution (SPA limitadas)
- âŒ Sin proxy rotation (puede ser bloqueado)
- âŒ Rate limiting puede afectar
- âŒ Google puede bloquear despuÃ©s de muchas requests
- âŒ No extrae contenido dinÃ¡mico (solo HTML estÃ¡tico)

---

## ğŸ”® Roadmap

### v1.1
- [ ] Retry con backoff exponencial
- [ ] Caching de resultados
- [ ] Better error handling

### v2.0
- [ ] Playwright/Selenium integration (si disponible)
- [ ] JavaScript rendering
- [ ] Proxy rotation

### v3.0
- [ ] Real-time alerts
- [ ] Trend monitoring
- [ ] NLP summaries
- [ ] PDF extraction

---

## ğŸ“ Estructura

```
web-research/
â”œâ”€â”€ research_engine.py       (Motor principal)
â”œâ”€â”€ research_cli.py          (CLI)
â”œâ”€â”€ research_agent.md        (DocumentaciÃ³n subagente)
â”œâ”€â”€ README.md               (Este archivo)
â”œâ”€â”€ requirements.txt
â””â”€â”€ results/
    â””â”€â”€ research_*.json     (Reportes)
```

---

## ğŸš€ Deploy

### Local
```bash
python research_cli.py "tu_query"
```

### Como Task Cron
```
@hourly python research_cli.py "market trends"
```

### Como Subagente
```python
await sessions_spawn(
    task="Investiga: [query]",
    agentId="research"
)
```

---

## ğŸ“ Ejemplos

### Ejemplo 1: BÃºsqueda Simple
```bash
$ python research_cli.py "FastAPI tutorial"

ğŸ” Buscando en Google: FastAPI tutorial
âœ… Encontrados: 10 resultados

1. FastAPI - The Modern Web Framework
   FastAPI is a modern web framework for building APIs...
   
2. FastAPI Tutorial - Full Course
   Learn FastAPI from scratch with this...
```

### Ejemplo 2: InvestigaciÃ³n Profunda
```bash
$ python research_cli.py "AI 2026" --depth 5

ğŸ”¬ INVESTIGACIÃ“N WEB: AI 2026
ğŸ“ STAGE 1: BÃšSQUEDA
âœ… Encontrados: 10 resultados

ğŸ“ STAGE 2: EXTRACCIÃ“N
âœ… ExtraÃ­dos: 5 contenidos

ğŸ“ STAGE 3: ANÃLISIS
âœ… Analizados: 5 documentos

ğŸ“Š REPORTE DE INVESTIGACIÃ“N
ğŸ” TÃ“PICO: AI 2026
   Fuentes encontradas: 10
   Contenido extraÃ­do: 5
   Relevancia promedio: 78.5%
```

### Ejemplo 3: InvestigaciÃ³n con SubtÃ³picos
```bash
$ python research_cli.py "Web3" --subs "blockchain,crypto,NFTs"

ğŸ”¬ INVESTIGACIÃ“N WEB: Web3
(investigaciÃ³n principal + 3 subtÃ³picos)

Resultados guardados en: results/research_*.json
```

---

## ğŸ› Troubleshooting

### "No se encontraron resultados"
```
âœ“ Intenta con una query mÃ¡s especÃ­fica
âœ“ Verifica conexiÃ³n a internet
âœ“ Google puede estar bloqueando (retry en 5 min)
```

### "Connection timeout"
```
âœ“ Aumenta timeout: timeout=30
âœ“ Aumenta delays: asyncio.sleep(5)
âœ“ Usa VPN o proxy
```

### "BeautifulSoup error"
```bash
pip install --break-system-packages lxml
```

---

## ğŸ’¡ Tips

1. **Queries especÃ­ficas** funcionan mejor
   ```
   âŒ "AI"
   âœ… "AI applications in healthcare 2026"
   ```

2. **Profundidad moderada** es mÃ¡s rÃ¡pido
   ```python
   depth=3   # RÃ¡pido, suficiente
   depth=10  # Lento, exhaustivo
   ```

3. **SubtÃ³picos ayudan** a investigaciones
   ```python
   research_topic(
       "Python",
       subtopics=["async", "web frameworks", "data science"]
   )
   ```

4. **Guarda resultados** para reutilizar
   ```python
   engine.save_research(research)  # JSON reutilizable
   ```

---

## ğŸ“„ Licencia

Open Source - Libre para usar y modificar

---

## ğŸ‘¨â€ğŸ’» Autor

**Anais** ğŸ  
Web Research Engine v1.0  
Enero 2026

---

**Â¡Listo para investigar!** ğŸ”¬ğŸš€
